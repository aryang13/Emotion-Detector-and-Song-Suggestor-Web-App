{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ModelSkeleton.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"3w-CXJzLLgD3"},"source":["import requests, re, time\n","import torch, torchvision\n","from torch import nn, optim\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QGIf1bvkyK2i"},"source":["#load dataset into directory from drive"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJmVliRfyPr_"},"source":["xform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()]) #primary transform"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mvoFvj8L0lrq"},"source":["According to the second link cited in the proposal, a grayscale transofrm on top of resizing has given the best results when comparing sentiments on faces\n"]},{"cell_type":"code","metadata":{"id":"PHVNAyeRIpVi"},"source":["#any possible data augmentation here:\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vg6Gsbhi0uX_"},"source":["dataset_full = datasets.ImageFolder('/content/drive/MyDrive/dataset', transform=xform) #retreive dataset, change location "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rFEp7rSQ0-j6"},"source":["n_all = len(dataset_full)\n","n_train = int(0.8 * n_all)\n","n_test = n_all - n_train\n","rng = torch.Generator().manual_seed(1549)\n","dataset_train, dataset_test = torch.utils.data.random_split(dataset_full, [n_train, n_test], rng)\n","loader_train = torch.utils.data.DataLoader(dataset_train, batch_size = 4, shuffle=True)\n","loader_test = torch.utils.data.DataLoader(dataset_test, batch_size = 4, shuffle=True) #prepare dataset by splitting, same as usual"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K8F226EV1I6D"},"source":["model = models.resnet18(pretrained=True) #will be doing transfer learning on resnet. "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cvylqylt1NVF"},"source":["as done in A2, need to modify layers to attain better accuracies later on. could experiment on raw resnet first and modify fc layers later on."]},{"cell_type":"code","metadata":{"id":"ss9A9YXc1YsM"},"source":["#code here for running test and model using cross entry loss\n","\n","\n","\n","\n","\n","\n","\n","#code here for optimizer and scheduler\n","\n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jVYDFrzWIegi"},"source":["# https://ieeexplore.ieee.org/document/8990979, maximum expected acc is 70% using resnet18 and kaggle dataset"],"execution_count":null,"outputs":[]}]}
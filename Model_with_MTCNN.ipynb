{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model_with_MTCNN.ipynb","provenance":[],"authorship_tag":"ABX9TyPnqYkl9hfSjwW3cFWsaxov"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"o00ao1pIpnRg","executionInfo":{"status":"ok","timestamp":1620460322421,"user_tz":-420,"elapsed":4588,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["import requests, re, time\n","import torch, torchvision\n","from torch import nn, optim\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYmF-BOVpxUH","executionInfo":{"status":"ok","timestamp":1620460343062,"user_tz":-420,"elapsed":20006,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"2ace3607-c2c9-4560-bcdf-05a6ed8cf779"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FhZrA-_p7z4","executionInfo":{"status":"ok","timestamp":1620459662567,"user_tz":-420,"elapsed":10704,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"59e24fc5-56ea-42c1-90f3-43cb23726846"},"source":["pip install mtcnn"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting mtcnn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 5.8MB/s \n","\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n","Installing collected packages: mtcnn\n","Successfully installed mtcnn-0.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOYIIlnnqFQz","executionInfo":{"status":"ok","timestamp":1620459664870,"user_tz":-420,"elapsed":11673,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"9db71777-7f27-4c94-d9a8-07cac9d2e09e"},"source":["import mtcnn\n","print(mtcnn.__version__)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["0.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3GfGqGDyqLZF","executionInfo":{"status":"ok","timestamp":1620459664872,"user_tz":-420,"elapsed":9588,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["#The MTCNN takes as a input a single image and outputs the bounding box coordinates for that image where the face is.\n","#The code below takes in an input directory and runs the MTCNN on all the images in that directory and outputs in \n","#output directory only the bounded images (only faces). \n","#link to code below: https://stackoverflow.com/questions/65105644/how-to-face-extraction-from-images-in-a-folder-with-mtcnn-in-python\n","\n","from mtcnn import MTCNN\n","import cv2\n","import os\n","def crop_image(source_dir, dest_dir, mode):\n","    if os.path.isdir(dest_dir)==False:\n","        os.mkdir(dest_dir)\n","    detector = MTCNN()\n","    source_list=os.listdir(source_dir)\n","    uncropped_file_list=[]\n","    for f in source_list:\n","        f_path=os.path.join(source_dir, f)\n","        dest_path=os.path.join(dest_dir,f)\n","        img=cv2.imread(f_path)\n","        try:\n","          data=detector.detect_faces(img)\n","        except:\n","          print(f_path)\n","          data==[]\n","          pass\n","        if data ==[]:\n","            uncropped_file_list.append(f_path)\n","        else:\n","            if mode==1:  #detect the box with the largest area\n","                for i, faces in enumerate(data): # iterate through all the faces found\n","                    box=faces['box']  # get the box for each face                \n","                    biggest=0                    \n","                    area = box[3]  * box[2]\n","                    if area>biggest:\n","                        biggest=area\n","                        bbox=box \n","                bbox[0]= 0 if bbox[0]<0 else bbox[0]\n","                bbox[1]= 0 if bbox[1]<0 else bbox[1]\n","                img=img[bbox[1]: bbox[1]+bbox[3],bbox[0]: bbox[0]+ bbox[2]] \n","                cv2.imwrite(dest_path, img)\n","            else:\n","                for i, faces in enumerate(data): # iterate through all the faces found\n","                    box=faces['box']\n","                    if box !=[]:\n","                        # return all faces found in the image\n","                        box[0]= 0 if box[0]<0 else box[0]\n","                        box[1]= 0 if box[1]<0 else box[1]\n","                        cropped_img=img[box[1]: box[1]+box[3],box[0]: box[0]+ box[2]]\n","                        fname=os.path.splitext(f)[0]\n","                        fext=os.path.splitext(f)[1]\n","                        fname=fname + str(i) + fext\n","                        save_path=os.path.join(dest_dir,fname )\n","                        cv2.imwrite(save_path, cropped_img)  \n","       \n","    return uncropped_file_list"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJ2OfHF_sQaR","executionInfo":{"status":"ok","timestamp":1620457112249,"user_tz":-420,"elapsed":328745,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"fbbf101c-7621-4e72-85ef-f2e46fd8b022"},"source":["source_dir = '/content/drive/MyDrive/dataset/happy'\n","dest_dir = '/content/drive/MyDrive/dataset_faces_only/happy'\n","uncropped_files_list=crop_image(source_dir, dest_dir,1)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 2980 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e5fdd58c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 2981 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e127fe320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8PAbOI7slqA","executionInfo":{"status":"ok","timestamp":1620457442030,"user_tz":-420,"elapsed":291932,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"c6177f1d-07e2-4a71-acc5-dc581fa40059"},"source":["source_dir = '/content/drive/MyDrive/dataset/sad'\n","dest_dir = '/content/drive/MyDrive/dataset_faces_only/sad'\n","uncropped_files_list=crop_image(source_dir, dest_dir,1)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5304 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e12594f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 5305 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e0f362830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXzhN0njzA0I","executionInfo":{"status":"ok","timestamp":1620457882599,"user_tz":-420,"elapsed":297120,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"c2bd40c5-83a4-4626-8019-610eee99ab7c"},"source":["source_dir = '/content/drive/MyDrive/dataset/angry'\n","dest_dir = '/content/drive/MyDrive/dataset_faces_only/angry'\n","uncropped_files_list=crop_image(source_dir, dest_dir,1)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 2800 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e11636560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 2801 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e11636b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ue2qHiPe0e2m","executionInfo":{"status":"ok","timestamp":1620460062268,"user_tz":-420,"elapsed":397359,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"fe295d36-8374-4e55-fe58-285785ac4b19"},"source":["source_dir = '/content/drive/MyDrive/dataset/neutral'\n","dest_dir = '/content/drive/MyDrive/dataset_faces_only/neutral'\n","uncropped_files_list=crop_image(source_dir, dest_dir,1)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd5dabde290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q_KJ0up48qG8","executionInfo":{"status":"ok","timestamp":1620467944049,"user_tz":-420,"elapsed":1031,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["xform = transforms.Compose([torchvision.transforms.Resize((225,225)),torchvision.transforms.RandomCrop(224),transforms.ToTensor()])\n","dataset_full = datasets.ImageFolder('/content/drive/MyDrive/dataset_faces_only', transform=xform)"],"execution_count":262,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WNy90ej9CS4","executionInfo":{"status":"ok","timestamp":1620467944649,"user_tz":-420,"elapsed":1437,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"2a47052d-8603-4a7c-beef-8a49bcb8feb0"},"source":["dataset_full"],"execution_count":263,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset ImageFolder\n","    Number of datapoints: 2085\n","    Root location: /content/drive/MyDrive/dataset_faces_only\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(225, 225), interpolation=bilinear)\n","               RandomCrop(size=(224, 224), padding=None)\n","               ToTensor()\n","           )"]},"metadata":{"tags":[]},"execution_count":263}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzzJ7gfj9DDb","executionInfo":{"status":"ok","timestamp":1620467944650,"user_tz":-420,"elapsed":1300,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"9e3aadb7-6f30-499a-e4f3-67264d054cec"},"source":["dataset_full.class_to_idx"],"execution_count":264,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'angry': 0, 'happy': 1, 'neutral': 2, 'sad': 3}"]},"metadata":{"tags":[]},"execution_count":264}]},{"cell_type":"code","metadata":{"id":"SGBl8rdW9K08","executionInfo":{"status":"ok","timestamp":1620467944651,"user_tz":-420,"elapsed":1102,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["n_all = len(dataset_full)\n","n_train = int(0.8 * n_all)\n","n_test = n_all - n_train\n","rng = torch.Generator().manual_seed(1549)\n","dataset_train, dataset_test = torch.utils.data.random_split(dataset_full, [n_train, n_test], rng)\n","loader_train = torch.utils.data.DataLoader(dataset_train, batch_size = 4, shuffle=True)\n","loader_test = torch.utils.data.DataLoader(dataset_test, batch_size = 4, shuffle=True) #prepare dataset by splitting, same as usual"],"execution_count":265,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZIr1bDu09Np7","executionInfo":{"status":"ok","timestamp":1620467945115,"user_tz":-420,"elapsed":1405,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"8160e6db-eb85-49f3-b1c8-8f117da5e975"},"source":["model = models.resnet18(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, 4)\n","torch.nn.init.xavier_uniform_(model.fc.weight)"],"execution_count":266,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[ 0.0463, -0.0249, -0.0940,  ..., -0.0301,  0.0288, -0.0884],\n","        [ 0.0950,  0.0081, -0.0390,  ..., -0.0797,  0.0117, -0.0404],\n","        [ 0.1006,  0.0299,  0.1053,  ..., -0.0930, -0.0755, -0.0026],\n","        [ 0.0287, -0.0315,  0.0011,  ...,  0.0014,  0.0709, -0.0419]],\n","       requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":266}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wa26D149RG9","executionInfo":{"status":"ok","timestamp":1620467945116,"user_tz":-420,"elapsed":1081,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"a3973ff9-2f90-4ae4-9dc3-05fd5a1196c9"},"source":["torch.cuda.device_count()"],"execution_count":267,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":267}]},{"cell_type":"code","metadata":{"id":"FJfo6bK99UPv","executionInfo":{"status":"ok","timestamp":1620467945664,"user_tz":-420,"elapsed":1479,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["device = torch.device('cuda:0')\n","model = model.to(device)"],"execution_count":268,"outputs":[]},{"cell_type":"code","metadata":{"id":"tOttN-lB9VrR","executionInfo":{"status":"ok","timestamp":1620467945667,"user_tz":-420,"elapsed":1286,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["criterion = nn.CrossEntropyLoss()\n","\n","def run_test(model):\n","    nsamples_test = len(dataset_test)\n","    loss, correct = 0, 0\n","    model.eval()\n","    with torch.no_grad():\n","        for samples, labels in loader_test:\n","            samples = samples.to(device)\n","            labels = labels.to(device)\n","            outs = model(samples)\n","            loss += criterion(outs, labels)\n","            _, preds = torch.max(outs.detach(), 1)\n","            correct_mask = preds == labels\n","            correct += correct_mask.sum(0).item()\n","    return loss / nsamples_test, correct / nsamples_test"],"execution_count":269,"outputs":[]},{"cell_type":"code","metadata":{"id":"UaedYdVu9XFI","executionInfo":{"status":"ok","timestamp":1620467945668,"user_tz":-420,"elapsed":1142,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"],"execution_count":270,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cm4b2BZ29Ybv","executionInfo":{"status":"ok","timestamp":1620467945668,"user_tz":-420,"elapsed":933,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["def run_train(model, opt, sched):\n","    nsamples_train = len(dataset_train)\n","    loss_sofar, correct_sofar = 0, 0\n","    model.train()\n","    with torch.enable_grad():\n","        for samples, labels in loader_train:\n","            samples = samples.to(device)\n","            labels = labels.to(device)\n","            opt.zero_grad()\n","            outs = model(samples)\n","            _, preds = torch.max(outs.detach(), 1)\n","            loss = criterion(outs, labels)\n","            loss.backward()\n","            opt.step()\n","            loss_sofar += loss.item() * samples.size(0)\n","            correct_sofar += torch.sum(preds == labels.detach())\n","    sched.step()\n","    return loss_sofar / nsamples_train, correct_sofar / nsamples_train"],"execution_count":271,"outputs":[]},{"cell_type":"code","metadata":{"id":"366oJ1WO9Z2t","executionInfo":{"status":"ok","timestamp":1620467946044,"user_tz":-420,"elapsed":1160,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["def run_all(model, optimizer, scheduler, n_epochs):\n","    for epoch in range(n_epochs):\n","        loss_train, acc_train = run_train(model, optimizer, scheduler)\n","        loss_test, acc_test = run_test(model)\n","        print(f\"epoch {epoch}: train loss {loss_train:.4f} acc {acc_train:.4f}, test loss {loss_test:.4f} acc {acc_test:.4f}\")"],"execution_count":272,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-RLijQZ9bPS","executionInfo":{"status":"ok","timestamp":1620467948237,"user_tz":-420,"elapsed":3202,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"64ae0c91-8dad-4588-dcfe-2fcd597e854b"},"source":["run_test(model)"],"execution_count":273,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.5446, device='cuda:0'), 0.2541966426858513)"]},"metadata":{"tags":[]},"execution_count":273}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mp0v8X0o9cnj","executionInfo":{"status":"ok","timestamp":1620468157867,"user_tz":-420,"elapsed":212548,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"1c30e776-bf24-486f-e2a7-8945340512a3"},"source":["run_all(model, optimizer, scheduler, 15)"],"execution_count":274,"outputs":[{"output_type":"stream","text":["epoch 0: train loss 1.1867 acc 0.5755, test loss 0.1940 acc 0.7290\n","epoch 1: train loss 0.7441 acc 0.7326, test loss 0.1541 acc 0.7410\n","epoch 2: train loss 0.5682 acc 0.7926, test loss 0.1230 acc 0.8249\n","epoch 3: train loss 0.3563 acc 0.8843, test loss 0.1112 acc 0.8082\n","epoch 4: train loss 0.2497 acc 0.9167, test loss 0.1280 acc 0.8345\n","epoch 5: train loss 0.1490 acc 0.9454, test loss 0.1192 acc 0.8417\n","epoch 6: train loss 0.1470 acc 0.9586, test loss 0.1125 acc 0.8513\n","epoch 7: train loss 0.1034 acc 0.9736, test loss 0.0972 acc 0.8657\n","epoch 8: train loss 0.0990 acc 0.9754, test loss 0.1284 acc 0.8489\n","epoch 9: train loss 0.1150 acc 0.9682, test loss 0.1012 acc 0.8681\n","epoch 10: train loss 0.0820 acc 0.9766, test loss 0.1115 acc 0.8441\n","epoch 11: train loss 0.0614 acc 0.9844, test loss 0.0980 acc 0.8705\n","epoch 12: train loss 0.0748 acc 0.9802, test loss 0.1129 acc 0.8585\n","epoch 13: train loss 0.0766 acc 0.9802, test loss 0.1240 acc 0.8393\n","epoch 14: train loss 0.0743 acc 0.9778, test loss 0.1030 acc 0.8609\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7kQcCZh2cshz","executionInfo":{"status":"ok","timestamp":1620468592505,"user_tz":-420,"elapsed":735,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["torch.save(model,'/content/drive/MyDrive/Colab Notebooks/model.pt')"],"execution_count":275,"outputs":[]}]}
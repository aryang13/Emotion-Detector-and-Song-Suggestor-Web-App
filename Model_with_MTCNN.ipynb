{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model_with_MTCNN.ipynb","provenance":[],"authorship_tag":"ABX9TyO6GBIkSZ+/9tFw7SfF1IsK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"o00ao1pIpnRg","executionInfo":{"status":"ok","timestamp":1621093358753,"user_tz":-420,"elapsed":7636,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["import requests, re, time\n","import torch, torchvision\n","from torch import nn, optim\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RYmF-BOVpxUH","executionInfo":{"status":"ok","timestamp":1621093381776,"user_tz":-420,"elapsed":30609,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"b19d589a-2f56-4742-bf16-e80a18af81f6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FhZrA-_p7z4","executionInfo":{"status":"ok","timestamp":1620459662567,"user_tz":-420,"elapsed":10704,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"59e24fc5-56ea-42c1-90f3-43cb23726846"},"source":["pip install mtcnn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting mtcnn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 5.8MB/s \n","\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n","Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.19.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n","Installing collected packages: mtcnn\n","Successfully installed mtcnn-0.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOYIIlnnqFQz","executionInfo":{"status":"ok","timestamp":1620459664870,"user_tz":-420,"elapsed":11673,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"9db71777-7f27-4c94-d9a8-07cac9d2e09e"},"source":["import mtcnn\n","print(mtcnn.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3GfGqGDyqLZF"},"source":["#The MTCNN takes as a input a single image and outputs the bounding box coordinates for that image where the face is.\n","#The code below takes in an input directory and runs the MTCNN on all the images in that directory and outputs in \n","#output directory only the bounded images (only faces). \n","#link to code below: https://stackoverflow.com/questions/65105644/how-to-face-extraction-from-images-in-a-folder-with-mtcnn-in-python\n","\n","from mtcnn import MTCNN\n","import cv2\n","import os\n","def crop_image(source_dir, dest_dir, mode):\n","    if os.path.isdir(dest_dir)==False:\n","        os.mkdir(dest_dir)\n","    detector = MTCNN()\n","    source_list=os.listdir(source_dir)\n","    uncropped_file_list=[]\n","    for f in source_list:\n","        f_path=os.path.join(source_dir, f)\n","        dest_path=os.path.join(dest_dir,f)\n","        img=cv2.imread(f_path)\n","        try:\n","          data=detector.detect_faces(img)\n","        except:\n","          print(f_path)\n","          data==[]\n","          pass\n","        if data ==[]:\n","            uncropped_file_list.append(f_path)\n","        else:\n","            if mode==1:  #detect the box with the largest area\n","                for i, faces in enumerate(data): # iterate through all the faces found\n","                    box=faces['box']  # get the box for each face                \n","                    biggest=0                    \n","                    area = box[3]  * box[2]\n","                    if area>biggest:\n","                        biggest=area\n","                        bbox=box \n","                bbox[0]= 0 if bbox[0]<0 else bbox[0]\n","                bbox[1]= 0 if bbox[1]<0 else bbox[1]\n","                img=img[bbox[1]: bbox[1]+bbox[3],bbox[0]: bbox[0]+ bbox[2]] \n","                cv2.imwrite(dest_path, img)\n","            else:\n","                for i, faces in enumerate(data): # iterate through all the faces found\n","                    box=faces['box']\n","                    if box !=[]:\n","                        # return all faces found in the image\n","                        box[0]= 0 if box[0]<0 else box[0]\n","                        box[1]= 0 if box[1]<0 else box[1]\n","                        cropped_img=img[box[1]: box[1]+box[3],box[0]: box[0]+ box[2]]\n","                        fname=os.path.splitext(f)[0]\n","                        fext=os.path.splitext(f)[1]\n","                        fname=fname + str(i) + fext\n","                        save_path=os.path.join(dest_dir,fname )\n","                        cv2.imwrite(save_path, cropped_img)  \n","       \n","    return uncropped_file_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJ2OfHF_sQaR","executionInfo":{"status":"ok","timestamp":1620457112249,"user_tz":-420,"elapsed":328745,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"fbbf101c-7621-4e72-85ef-f2e46fd8b022"},"source":["source_dir = '/content/drive/MyDrive/dataset/happy'\n","dest_dir = '/content/drive/MyDrive/dataset_faces_only/happy'\n","uncropped_files_list=crop_image(source_dir, dest_dir,1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 2980 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e5fdd58c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 2981 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e127fe320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8PAbOI7slqA","executionInfo":{"status":"ok","timestamp":1620457442030,"user_tz":-420,"elapsed":291932,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"c6177f1d-07e2-4a71-acc5-dc581fa40059"},"source":["source_dir = '/content/drive/MyDrive/dataset/sad'\n","dest_dir = '/content/drive/MyDrive/dataset_faces_only/sad'\n","uncropped_files_list=crop_image(source_dir, dest_dir,1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5304 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e12594f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 5305 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e0f362830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CXzhN0njzA0I","executionInfo":{"status":"ok","timestamp":1620457882599,"user_tz":-420,"elapsed":297120,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"c2bd40c5-83a4-4626-8019-610eee99ab7c"},"source":["source_dir = '/content/drive/MyDrive/dataset/angry'\n","dest_dir = '/content/drive/MyDrive/dataset_faces_only/angry'\n","uncropped_files_list=crop_image(source_dir, dest_dir,1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 2800 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e11636560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 2801 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2e11636b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ue2qHiPe0e2m","executionInfo":{"status":"ok","timestamp":1620460062268,"user_tz":-420,"elapsed":397359,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"fe295d36-8374-4e55-fe58-285785ac4b19"},"source":["source_dir = '/content/drive/MyDrive/dataset/neutral'\n","dest_dir = '/content/drive/MyDrive/dataset_faces_only/neutral'\n","uncropped_files_list=crop_image(source_dir, dest_dir,1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd5dabde290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q_KJ0up48qG8","executionInfo":{"status":"ok","timestamp":1621107761006,"user_tz":-420,"elapsed":991,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["xform = transforms.Compose([torchvision.transforms.Resize((224,224)),torchvision.transforms.RandomHorizontalFlip(),torchvision.transforms.RandomRotation(15), transforms.ToTensor()])\n","dataset_full = datasets.ImageFolder('/content/drive/MyDrive/dataset_faces_only', transform=xform)"],"execution_count":198,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WNy90ej9CS4","executionInfo":{"status":"ok","timestamp":1621107761670,"user_tz":-420,"elapsed":1420,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"ed9f687c-0596-42fd-b1d3-68bbc367a153"},"source":["dataset_full"],"execution_count":199,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset ImageFolder\n","    Number of datapoints: 2085\n","    Root location: /content/drive/MyDrive/dataset_faces_only\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(224, 224), interpolation=bilinear)\n","               RandomHorizontalFlip(p=0.5)\n","               RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n","               ToTensor()\n","           )"]},"metadata":{"tags":[]},"execution_count":199}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jzzJ7gfj9DDb","executionInfo":{"status":"ok","timestamp":1621107761671,"user_tz":-420,"elapsed":1215,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"a2079949-a4f2-4362-a8fa-d3773d8422af"},"source":["dataset_full.class_to_idx"],"execution_count":200,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'angry': 0, 'happy': 1, 'neutral': 2, 'sad': 3}"]},"metadata":{"tags":[]},"execution_count":200}]},{"cell_type":"code","metadata":{"id":"SGBl8rdW9K08","executionInfo":{"status":"ok","timestamp":1621107762142,"user_tz":-420,"elapsed":1475,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["n_all = len(dataset_full)\n","n_train = int(0.8 * n_all)\n","n_test = n_all - n_train\n","rng = torch.Generator().manual_seed(1549)\n","dataset_train, dataset_test = torch.utils.data.random_split(dataset_full, [n_train, n_test], rng)\n","loader_train = torch.utils.data.DataLoader(dataset_train, batch_size = 4, shuffle=True)\n","loader_test = torch.utils.data.DataLoader(dataset_test, batch_size = 4, shuffle=True) #prepare dataset by splitting, same as usual"],"execution_count":201,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZIr1bDu09Np7","executionInfo":{"status":"ok","timestamp":1621107762746,"user_tz":-420,"elapsed":1818,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["model = models.resnet18(pretrained=True)\n","model.avgpool.output_size=(None,None)\n","model.fc = torch.nn.Sequential(torch.nn.Linear(25088,2508),torch.nn.ReLU(),torch.nn.Linear(2508,250),torch.nn.ReLU(),torch.nn.Linear(250,4))"],"execution_count":202,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_wa26D149RG9","executionInfo":{"status":"ok","timestamp":1621107762746,"user_tz":-420,"elapsed":1596,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"cdeacade-8596-4cb3-c94a-f40e5461eb44"},"source":["torch.cuda.device_count()"],"execution_count":203,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":203}]},{"cell_type":"code","metadata":{"id":"FJfo6bK99UPv","executionInfo":{"status":"ok","timestamp":1621107762747,"user_tz":-420,"elapsed":1433,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["device = torch.device('cuda:0')\n","model = model.to(device)"],"execution_count":204,"outputs":[]},{"cell_type":"code","metadata":{"id":"tOttN-lB9VrR","executionInfo":{"status":"ok","timestamp":1621107763135,"user_tz":-420,"elapsed":1543,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["criterion = nn.CrossEntropyLoss()\n","\n","def run_test(model):\n","    nsamples_test = len(dataset_test)\n","    loss, correct = 0, 0\n","    model.eval()\n","    with torch.no_grad():\n","        for samples, labels in loader_test:\n","            samples = samples.to(device)\n","            labels = labels.to(device)\n","            outs = model(samples)\n","            loss += criterion(outs, labels)\n","            _, preds = torch.max(outs.detach(), 1)\n","            correct_mask = preds == labels\n","            correct += correct_mask.sum(0).item()\n","    return loss / nsamples_test, correct / nsamples_test"],"execution_count":205,"outputs":[]},{"cell_type":"code","metadata":{"id":"UaedYdVu9XFI","executionInfo":{"status":"ok","timestamp":1621107764985,"user_tz":-420,"elapsed":3176,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"],"execution_count":206,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cm4b2BZ29Ybv","executionInfo":{"status":"ok","timestamp":1621107764986,"user_tz":-420,"elapsed":2997,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["def run_train(model, opt, sched):\n","    nsamples_train = len(dataset_train)\n","    loss_sofar, correct_sofar = 0, 0\n","    model.train()\n","    with torch.enable_grad():\n","        for samples, labels in loader_train:\n","            samples = samples.to(device)\n","            labels = labels.to(device)\n","            opt.zero_grad()\n","            outs = model(samples)\n","            _, preds = torch.max(outs.detach(), 1)\n","            loss = criterion(outs, labels)\n","            loss.backward()\n","            opt.step()\n","            loss_sofar += loss.item() * samples.size(0)\n","            correct_sofar += torch.sum(preds == labels.detach())\n","    sched.step()\n","    return loss_sofar / nsamples_train, correct_sofar / nsamples_train"],"execution_count":207,"outputs":[]},{"cell_type":"code","metadata":{"id":"366oJ1WO9Z2t","executionInfo":{"status":"ok","timestamp":1621107764986,"user_tz":-420,"elapsed":2765,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}}},"source":["def run_all(model, optimizer, scheduler, n_epochs):\n","    for epoch in range(n_epochs):\n","        loss_train, acc_train = run_train(model, optimizer, scheduler)\n","        loss_test, acc_test = run_test(model)\n","        print(f\"epoch {epoch}: train loss {loss_train:.4f} acc {acc_train:.4f}, test loss {loss_test:.4f} acc {acc_test:.4f}\")"],"execution_count":208,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-RLijQZ9bPS","executionInfo":{"status":"ok","timestamp":1621107769215,"user_tz":-420,"elapsed":6745,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"cedf6516-064b-4cbc-bfea-97a4130736db"},"source":["run_test(model)"],"execution_count":209,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor(0.3508, device='cuda:0'), 0.22302158273381295)"]},"metadata":{"tags":[]},"execution_count":209}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mp0v8X0o9cnj","executionInfo":{"status":"ok","timestamp":1621108671405,"user_tz":-420,"elapsed":908351,"user":{"displayName":"Deepan Chakravarthy","photoUrl":"","userId":"06081657364465504237"}},"outputId":"93911e5b-403e-493d-8ee8-511483e00a0c"},"source":["run_all(model, optimizer, scheduler, 20)"],"execution_count":210,"outputs":[{"output_type":"stream","text":["epoch 0: train loss 1.0243 acc 0.5516, test loss 0.1909 acc 0.6763\n","epoch 1: train loss 0.6802 acc 0.7440, test loss 0.1680 acc 0.7338\n","epoch 2: train loss 0.5421 acc 0.8040, test loss 0.1460 acc 0.7770\n","epoch 3: train loss 0.4281 acc 0.8531, test loss 0.1706 acc 0.7434\n","epoch 4: train loss 0.3786 acc 0.8609, test loss 0.1952 acc 0.7386\n","epoch 5: train loss 0.2609 acc 0.9125, test loss 0.1046 acc 0.8345\n","epoch 6: train loss 0.1899 acc 0.9359, test loss 0.1051 acc 0.8417\n","epoch 7: train loss 0.1576 acc 0.9442, test loss 0.0967 acc 0.8585\n","epoch 8: train loss 0.1461 acc 0.9520, test loss 0.1112 acc 0.8225\n","epoch 9: train loss 0.1367 acc 0.9526, test loss 0.1037 acc 0.8489\n","epoch 10: train loss 0.1266 acc 0.9526, test loss 0.1117 acc 0.8297\n","epoch 11: train loss 0.1299 acc 0.9466, test loss 0.1160 acc 0.8345\n","epoch 12: train loss 0.1102 acc 0.9640, test loss 0.1109 acc 0.8513\n","epoch 13: train loss 0.1032 acc 0.9646, test loss 0.1146 acc 0.8345\n","epoch 14: train loss 0.1192 acc 0.9568, test loss 0.1108 acc 0.8369\n","epoch 15: train loss 0.1087 acc 0.9598, test loss 0.1152 acc 0.8417\n","epoch 16: train loss 0.1210 acc 0.9532, test loss 0.1099 acc 0.8393\n","epoch 17: train loss 0.0956 acc 0.9664, test loss 0.1075 acc 0.8465\n","epoch 18: train loss 0.1024 acc 0.9598, test loss 0.1080 acc 0.8609\n","epoch 19: train loss 0.1156 acc 0.9580, test loss 0.1160 acc 0.8225\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7kQcCZh2cshz"},"source":["  torch.save(model,'/content/drive/MyDrive/Colab Notebooks/model.pt')"],"execution_count":null,"outputs":[]}]}